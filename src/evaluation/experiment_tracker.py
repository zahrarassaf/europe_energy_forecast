import pandas as pd
import numpy as np
import random
import yaml
from sklearn.model_selection import TimeSeriesSplit
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import matplotlib.pyplot as plt
from datetime import datetime
import warnings
import gc
import os
import json
import argparse
import hashlib
from scipy import stats
from statsmodels.tsa.arima.model import ARIMA
from scipy.stats import wilcoxon, norm
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
import xgboost as xgb
import lightgbm as lgb
from statsmodels.tsa.holtwinters import ExponentialSmoothing
import itertools
import psutil
import signal
import sys

warnings.filterwarnings('ignore')

# ============================================================================
# WINDOWS OPTIMIZATIONS
# ============================================================================
os.environ['OMP_NUM_THREADS'] = '1'
os.environ['TF_NUM_INTEROP_THREADS'] = '1'
os.environ['TF_NUM_INTRAOP_THREADS'] = '1'
os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'
os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'

gc.enable()
gc.set_threshold(100, 5, 5)

# ============================================================================
# REPRODUCIBILITY AND DETERMINISM
# ============================================================================
BASE_SEED = 42
N_SEEDS = 5

def set_seed(seed):
    random.seed(seed)
    np.random.seed(seed)
    tf.random.set_seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    os.environ['TF_DETERMINISTIC_OPS'] = '1'
    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'
    tf.config.threading.set_inter_op_parallelism_threads(1)
    tf.config.threading.set_intra_op_parallelism_threads(1)
    tf.config.experimental.enable_op_determinism()

set_seed(BASE_SEED)

def check_memory_and_clear(force=False):
    """Monitor memory usage and force cleanup if needed."""
    try:
        process = psutil.Process()
        mem_gb = process.memory_info().rss / 1024 / 1024 / 1024
        if mem_gb > 5 or force:
            print(f"Memory usage: {mem_gb:.2f} GB - Cleaning up...")
            tf.keras.backend.clear_session()
            for _ in range(3):
                gc.collect()
            return True
    except:
        pass
    return False

try:
    from prophet import Prophet
    PROPHET_AVAILABLE = True
except ImportError:
    PROPHET_AVAILABLE = False
    print("Prophet not available. Prophet baseline disabled.")

try:
    import optuna
    OPTUNA_AVAILABLE = True
except ImportError:
    OPTUNA_AVAILABLE = False
    print("Optuna not available. Hyperparameter optimization disabled.")


# ============================================================================
# CONFIGURATION MANAGEMENT
# ============================================================================

class Config:
    @staticmethod
    def load_from_yaml(path):
        with open(path, 'r') as f:
            config = yaml.safe_load(f)
        return config
    
    @staticmethod
    def get_default_config():
        return {
            "data_path": None,
            "country_code": "AT",
            "sequence_length": 24,
            "forecast_horizon": 6,
            "test_size": 0.2,
            "val_size": 0.1,
            "model_type": "enhanced_lstm",
            "lstm_units_1": 128,
            "lstm_units_2": 64,
            "dense_units_1": 64,
            "dense_units_2": 32,
            "cnn_filters_1": 64,
            "cnn_filters_2": 32,
            "kernel_size": 3,
            "attention_heads": 4,
            "dropout_rate": 0.3,
            "recurrent_dropout": 0.1,
            "l2_regularization": 0.0001,
            "learning_rate": 0.001,
            "batch_size": 64,
            "epochs": 200,
            "patience": 30,
            "min_delta": 0.0001,
            "gradient_clip": 1.0,
            "use_features": True,
            "n_fourier_terms": 6,
            "fourier_periods": [24, 168, 8760],
            "use_attention": True,
            "use_bidirectional": True,
            "use_residual": True,
            "use_multi_head_attention": True,
            "n_seeds": N_SEEDS,
            "optimize_hyperparameters": False,
            "n_trials": 50,
            "n_folds_cv": 5,
            "seed": BASE_SEED,
            "deterministic": True,
            "log_var_clip_min": -5,
            "log_var_clip_max": 5,
            "quantiles": [0.1, 0.5, 0.9],
            "seasonal_period": 24
        }


# ============================================================================
# UTILITY FUNCTIONS
# ============================================================================

def compute_dataset_hash(df):
    return hashlib.sha256(pd.util.hash_pandas_object(df, index=True).values).hexdigest()

def create_sequences_vectorized(data, seq_len, horizon):
    """Vectorized sequence creation with NO padding."""
    n_samples = len(data) - seq_len - horizon + 1
    if n_samples <= 0:
        return None, None
    
    indices = np.arange(n_samples)[:, None] + np.arange(seq_len)
    X = data[indices]
    
    target_indices = np.arange(n_samples)[:, None] + np.arange(seq_len, seq_len + horizon)
    y = data[target_indices]
    
    return X, y

def diebold_mariano_test(y_true, y_pred1, y_pred2, h=1):
    y_true = np.asarray(y_true).flatten()
    y_pred1 = np.asarray(y_pred1).flatten()
    y_pred2 = np.asarray(y_pred2).flatten()
    
    min_len = min(len(y_true), len(y_pred1), len(y_pred2))
    y_true = y_true[:min_len]
    y_pred1 = y_pred1[:min_len]
    y_pred2 = y_pred2[:min_len]
    
    e1 = y_true - y_pred1
    e2 = y_true - y_pred2
    d = e1**2 - e2**2
    d = d[~np.isnan(d)]
    
    if len(d) < 2:
        return 0.0, 1.0
    
    d_bar = np.mean(d)
    n = len(d)
    var_d = np.var(d, ddof=1)
    
    if h > 1 and n > h:
        autocov = 0
        for lag in range(1, min(h, n)):
            if lag < len(d):
                cov = np.cov(d[:-lag], d[lag:])[0, 1] if len(d[:-lag]) > 1 else 0
                autocov += (1 - lag/(h+1)) * cov
        var_d = var_d + 2 * autocov
    
    dm_stat = d_bar / np.sqrt(var_d / n) if var_d > 0 else 0
    p_value = 2 * (1 - stats.norm.cdf(abs(dm_stat)))
    
    return dm_stat, p_value

def holm_bonferroni_correction(p_values, alpha=0.05):
    n_tests = len(p_values)
    sorted_idx = np.argsort(p_values)
    sorted_p = np.array(p_values)[sorted_idx]
    
    reject = np.zeros(n_tests, dtype=bool)
    for i, p in enumerate(sorted_p):
        if p < alpha / (n_tests - i):
            reject[sorted_idx[i]] = True
    
    return reject.tolist()

def moving_block_bootstrap(data, block_size=None, n_bootstrap=1000, ci=0.95, seasonal_period=24):
    """
    Moving block bootstrap for time series data with adaptive block size.
    Preserves autocorrelation structure.
    """
    if block_size is None:
        block_size = seasonal_period
    
    n = len(data)
    n_blocks = int(np.ceil(n / block_size))
    bootstrap_stats = []
    
    for _ in range(n_bootstrap):
        blocks = []
        for _ in range(n_blocks):
            start = np.random.randint(0, max(1, n - block_size))
            blocks.append(data[start:start+block_size])
        bootstrap_sample = np.concatenate(blocks)[:n]
        bootstrap_stats.append(np.mean(bootstrap_sample))
    
    alpha = (1 - ci) / 2
    lower = np.percentile(bootstrap_stats, alpha * 100)
    upper = np.percentile(bootstrap_stats, (1 - alpha) * 100)
    
    return lower, upper

def quantile_loss(y_true, y_pred, quantile):
    """Proper quantile loss for quantile regression."""
    error = y_true - y_pred
    return np.mean(np.maximum(quantile * error, (quantile - 1) * error))


# ============================================================================
# LEAKAGE-FREE DATA PROCESSOR - FIXED ALIGNMENT
# ============================================================================

class LeakageFreeProcessor:
    def __init__(self, config):
        self.config = config
        self.data = None
        self.target_scaler = None
        self.feature_scalers = {}
        self.fourier_params = None
        self.dataset_hash = None
        self.feature_stats = {}
        
    def load_data(self, data_path=None):
        if data_path and os.path.exists(data_path):
            print(f"Loading data from: {data_path}")
            self.data = pd.read_csv(data_path, low_memory=False)
            
            if 'utc_timestamp' in self.data.columns:
                self.data['utc_timestamp'] = pd.to_datetime(self.data['utc_timestamp'])
                self.data.set_index('utc_timestamp', inplace=True)
        else:
            print("Data file not found. Creating sample dataset...")
            self.data = self._create_sample_dataset(20000)
        
        self.dataset_hash = compute_dataset_hash(self.data)
        print(f"Dataset hash: {self.dataset_hash}")
        print(f"Data shape: {self.data.shape}")
        print(f"Date range: {self.data.index.min()} to {self.data.index.max()}")
        
        return self.data
    
    def _create_sample_dataset(self, n_samples):
        np.random.seed(BASE_SEED)
        dates = pd.date_range('2015-01-01', periods=n_samples, freq='h')
        
        t = np.arange(n_samples)
        
        yearly = 5000 + 1000 * np.sin(2 * np.pi * t / (24 * 365))
        weekly = 300 * np.sin(2 * np.pi * t / (24 * 7))
        daily = 500 * np.sin(2 * np.pi * t / 24)
        trend = 0.001 * t
        noise_scale = 200 * (1 + 0.5 * np.sin(2 * np.pi * t / (24 * 30)))
        noise = np.random.normal(0, noise_scale, n_samples)
        
        load = yearly + daily + weekly + trend + noise
        
        df = pd.DataFrame({
            'AT_load_actual_entsoe_transparency': load,
            'AT_price_day_ahead': 50 + 10 * np.sin(2 * np.pi * t / 24) + np.random.normal(0, 5, n_samples),
            'AT_solar_generation_actual': 1000 * np.maximum(0, np.sin(2 * np.pi * (t % 24) / 24)) + np.random.normal(0, 50, n_samples),
            'AT_wind_onshore_generation_actual': 500 * (1 + 0.5 * np.random.randn(n_samples)),
            'DE_load_actual_entsoe_transparency': load * 5 + np.random.normal(0, 1000, n_samples),
            'FR_load_actual_entsoe_transparency': load * 4 + np.random.normal(0, 800, n_samples),
        }, index=dates)
        
        return df
    
    def get_target_column(self, country_code):
        return f"{country_code}_load_actual_entsoe_transparency"
    
    def get_feature_columns(self, country_code):
        prefix = f"{country_code}_"
        return [col for col in self.data.columns if col.startswith(prefix) and 
                col != self.get_target_column(country_code)]
    
    def prepare_splits(self, country_code):
        target_col = self.get_target_column(country_code)
        feature_cols = self.get_feature_columns(country_code)
        
        if target_col not in self.data.columns:
            raise ValueError(f"Target column {target_col} not found")
        
        print(f"\nPreparing splits for {country_code}")
        print(f"  Target: {target_col}")
        print(f"  Features: {len(feature_cols)} available")
        
        raw_df = self.data[[target_col] + feature_cols].copy()
        timestamps = self.data.index.copy()
        
        total_len = len(raw_df)
        test_size = self.config.get('test_size', 0.2)
        val_size = self.config.get('val_size', 0.1)
        
        train_end = int(total_len * (1 - test_size - val_size))
        val_end = train_end + int(total_len * val_size)
        
        train_raw_df = raw_df.iloc[:train_end].copy()
        val_raw_df = raw_df.iloc[train_end:val_end].copy()
        test_raw_df = raw_df.iloc[val_end:].copy()
        
        train_timestamps = timestamps[:train_end]
        val_timestamps = timestamps[train_end:val_end]
        test_timestamps = timestamps[val_end:]
        
        print(f"  Split sizes - Train: {len(train_raw_df)}, Val: {len(val_raw_df)}, Test: {len(test_raw_df)}")
        
        train_raw_df = self._handle_missing_values(train_raw_df, fit=True)
        val_raw_df = self._handle_missing_values(val_raw_df, fit=False)
        test_raw_df = self._handle_missing_values(test_raw_df, fit=False)
        
        train_target = train_raw_df[target_col].values
        val_target = val_raw_df[target_col].values
        test_target = test_raw_df[target_col].values
        
        self.target_scaler = StandardScaler()
        train_target_scaled = self.target_scaler.fit_transform(train_target.reshape(-1, 1)).flatten()
        val_target_scaled = self.target_scaler.transform(val_target.reshape(-1, 1)).flatten()
        test_target_scaled = self.target_scaler.transform(test_target.reshape(-1, 1)).flatten()
        
        train_features_scaled = None
        val_features_scaled = None
        test_features_scaled = None
        
        if feature_cols and self.config.get('use_features', True):
            print("  Processing features...")
            
            train_features = train_raw_df[feature_cols].values
            val_features = val_raw_df[feature_cols].values
            test_features = test_raw_df[feature_cols].values
            
            n_features = len(feature_cols)
            train_features_scaled = np.zeros_like(train_features, dtype=np.float32)
            val_features_scaled = np.zeros_like(val_features, dtype=np.float32)
            test_features_scaled = np.zeros_like(test_features, dtype=np.float32)
            
            for i in range(n_features):
                scaler = StandardScaler()
                train_features_scaled[:, i] = scaler.fit_transform(train_features[:, i].reshape(-1, 1)).flatten()
                val_features_scaled[:, i] = scaler.transform(val_features[:, i].reshape(-1, 1)).flatten()
                test_features_scaled[:, i] = scaler.transform(test_features[:, i].reshape(-1, 1)).flatten()
                self.feature_scalers[feature_cols[i]] = scaler
        
        fourier_train = None
        fourier_val = None
        fourier_test = None
        
        if self.config.get('use_features', True):
            print("  Adding Fourier features...")
            fourier_train, self.fourier_params = self._add_fourier_features(
                train_timestamps, fit=True
            )
            fourier_val, _ = self._add_fourier_features(
                val_timestamps, fit=False, params=self.fourier_params
            )
            fourier_test, _ = self._add_fourier_features(
                test_timestamps, fit=False, params=self.fourier_params
            )
        
        print("  Creating sequences with proper temporal alignment...")
        splits = self._create_sequences_aligned(
            train_target_scaled, val_target_scaled, test_target_scaled,
            train_features_scaled, val_features_scaled, test_features_scaled,
            fourier_train, fourier_val, fourier_test
        )
        
        splits['train_raw'] = train_target
        splits['val_raw'] = val_target
        splits['test_raw'] = test_target
        splits['train_timestamps'] = train_timestamps
        splits['val_timestamps'] = val_timestamps
        splits['test_timestamps'] = test_timestamps
        splits['feature_names'] = feature_cols
        splits['target_scaler'] = self.target_scaler
        
        print(f"  Final shapes:")
        print(f"    X_train: {splits['X_train'].shape}")
        print(f"    X_val: {splits['X_val'].shape}")
        print(f"    X_test: {splits['X_test'].shape}")
        print(f"    Features per timestep: {splits['X_train'].shape[2]}")
        
        return splits
    
    def _handle_missing_values(self, df, fit=True):
        df_clean = df.copy()
        
        for col in df_clean.columns:
            if df_clean[col].isna().any():
                if fit:
                    self.feature_stats[col] = {
                        'median': df_clean[col].median(),
                        'std': df_clean[col].std()
                    }
                    df_clean[col] = df_clean[col].fillna(df_clean[col].median())
                else:
                    if col in self.feature_stats:
                        df_clean[col] = df_clean[col].fillna(self.feature_stats[col]['median'])
                    else:
                        df_clean[col] = df_clean[col].fillna(0)
        
        return df_clean
    
    def _add_fourier_features(self, timestamps, fit=True, params=None):
        t_hours = (timestamps - timestamps[0]).total_seconds() / 3600.0
        
        if fit:
            params = {
                'min_t': t_hours.min(),
                'max_t': t_hours.max()
            }
            t_scaled = (t_hours - params['min_t']) / (params['max_t'] - params['min_t'] + 1e-8)
        else:
            t_scaled = (t_hours - params['min_t']) / (params['max_t'] - params['min_t'] + 1e-8)
        
        features = []
        periods = self.config.get('fourier_periods', [24, 168, 8760])
        max_harmonic = self.config.get('n_fourier_terms', 6)
        
        for period in periods:
            for k in range(1, max_harmonic + 1):
                features.append(np.sin(2 * np.pi * k * t_scaled / period))
                features.append(np.cos(2 * np.pi * k * t_scaled / period))
        
        return np.column_stack(features), params
    
    def _create_sequences_aligned(self, train_target, val_target, test_target,
                                  train_features, val_features, test_features,
                                  fourier_train, fourier_val, fourier_test):
        """
        Create sequences with PROPER TEMPORAL ALIGNMENT between target and features.
        
        CRITICAL FIX: Features and target must have the SAME temporal context.
        For validation: use train_tail + val for BOTH target and features.
        For test: use val_tail + test for BOTH target and features.
        """
        seq_len = self.config['sequence_length']
        horizon = self.config['forecast_horizon']
        
        # ========== 1. TRAIN SEQUENCES ==========
        X_train, y_train = create_sequences_vectorized(train_target, seq_len, horizon)
        
        if X_train is None:
            raise ValueError(f"Not enough training data. Need at least {seq_len + horizon} samples.")
        
        # Train features (if available)
        n_train = X_train.shape[0]
        if train_features is not None:
            # Vectorized indexing for speed
            train_indices = np.arange(n_train)[:, None] + np.arange(seq_len)
            X_train_feat = train_features[train_indices]
            n_feat = train_features.shape[1]
        else:
            X_train_feat = None
            n_feat = 0
        
        # Train Fourier (if available)
        if fourier_train is not None:
            train_fourier_indices = np.arange(n_train)[:, None] + np.arange(seq_len)
            X_train_fourier = fourier_train[train_fourier_indices]
            n_fourier = fourier_train.shape[1]
        else:
            X_train_fourier = None
            n_fourier = 0
        
        # ========== 2. VALIDATION SEQUENCES - CRITICAL FIX ==========
        # Combine train tail with validation for BOTH target and features
        val_target_with_context = np.concatenate([train_target[-seq_len:], val_target])
        X_val, y_val = create_sequences_vectorized(val_target_with_context, seq_len, horizon)
        n_val = X_val.shape[0]
        
        if val_features is not None:
            # SAME context for features
            val_features_with_context = np.concatenate([train_features[-seq_len:], val_features])
            val_indices = np.arange(n_val)[:, None] + np.arange(seq_len)
            X_val_feat = val_features_with_context[val_indices]
        else:
            X_val_feat = None
        
        if fourier_val is not None:
            # SAME context for Fourier features
            fourier_val_with_context = np.concatenate([fourier_train[-seq_len:], fourier_val])
            val_fourier_indices = np.arange(n_val)[:, None] + np.arange(seq_len)
            X_val_fourier = fourier_val_with_context[val_fourier_indices]
        else:
            X_val_fourier = None
        
        # ========== 3. TEST SEQUENCES - CRITICAL FIX ==========
        # Combine val tail with test for BOTH target and features
        test_target_with_context = np.concatenate([val_target[-seq_len:], test_target])
        X_test, y_test = create_sequences_vectorized(test_target_with_context, seq_len, horizon)
        n_test = X_test.shape[0]
        
        if test_features is not None:
            # SAME context for features
            test_features_with_context = np.concatenate([val_features[-seq_len:], test_features])
            test_indices = np.arange(n_test)[:, None] + np.arange(seq_len)
            X_test_feat = test_features_with_context[test_indices]
        else:
            X_test_feat = None
        
        if fourier_test is not None:
            # SAME context for Fourier features
            fourier_test_with_context = np.concatenate([fourier_val[-seq_len:], fourier_test])
            test_fourier_indices = np.arange(n_test)[:, None] + np.arange(seq_len)
            X_test_fourier = fourier_test_with_context[test_fourier_indices]
        else:
            X_test_fourier = None
        
        # ========== 4. COMBINE ALL FEATURES ==========
        total_features = 1 + n_feat + n_fourier
        
        X_train_combined = np.zeros((n_train, seq_len, total_features), dtype=np.float32)
        X_val_combined = np.zeros((n_val, seq_len, total_features), dtype=np.float32)
        X_test_combined = np.zeros((n_test, seq_len, total_features), dtype=np.float32)
        
        # Target values (always first channel)
        X_train_combined[:, :, 0] = X_train
        X_val_combined[:, :, 0] = X_val
        X_test_combined[:, :, 0] = X_test
        
        # Add regular features
        feat_idx = 1
        if X_train_feat is not None:
            X_train_combined[:, :, feat_idx:feat_idx+n_feat] = X_train_feat
            X_val_combined[:, :, feat_idx:feat_idx+n_feat] = X_val_feat
            X_test_combined[:, :, feat_idx:feat_idx+n_feat] = X_test_feat
            feat_idx += n_feat
        
        # Add Fourier features
        if X_train_fourier is not None:
            X_train_combined[:, :, feat_idx:feat_idx+n_fourier] = X_train_fourier
            X_val_combined[:, :, feat_idx:feat_idx+n_fourier] = X_val_fourier
            X_test_combined[:, :, feat_idx:feat_idx+n_fourier] = X_test_fourier
        
        return {
            'X_train': X_train_combined,
            'X_val': X_val_combined,
            'X_test': X_test_combined,
            'y_train': y_train,
            'y_val': y_val,
            'y_test': y_test
        }


# ============================================================================
# STRONG BASELINES
# ============================================================================

class StrongBaselines:
    def __init__(self, config):
        self.config = config
        self.best_params = {}
    
    def _prepare_tree_data_no_leakage(self, splits):
        """
        Prepare data for tree-based models with NO LEAKAGE.
        Lag features are built separately for each split.
        """
        # Train data - build lags on train only
        df_train = pd.DataFrame({
            'target': splits['train_raw'],
            'timestamp': splits['train_timestamps']
        })
        for lag in self.config.get('n_lags', [24, 48, 168]):
            if lag < len(df_train):
                df_train[f'lag_{lag}'] = df_train['target'].shift(lag)
        
        df_train['hour'] = df_train['timestamp'].dt.hour
        df_train['hour_sin'] = np.sin(2 * np.pi * df_train['hour'] / 24)
        df_train['hour_cos'] = np.cos(2 * np.pi * df_train['hour'] / 24)
        df_train = df_train.dropna()
        
        feature_cols = [c for c in df_train.columns if c not in ['target', 'timestamp', 'hour']]
        X_train = df_train[feature_cols].values
        y_train = df_train['target'].values
        
        # Validation data - use train's lag structure
        df_val = pd.DataFrame({
            'target': splits['val_raw'],
            'timestamp': splits['val_timestamps']
        })
        for lag in self.config.get('n_lags', [24, 48, 168]):
            if lag < len(df_val):
                df_val[f'lag_{lag}'] = df_val['target'].shift(lag)
        
        df_val['hour'] = df_val['timestamp'].dt.hour
        df_val['hour_sin'] = np.sin(2 * np.pi * df_val['hour'] / 24)
        df_val['hour_cos'] = np.cos(2 * np.pi * df_val['hour'] / 24)
        df_val = df_val.dropna()
        
        # Align features with train
        available_cols = [c for c in feature_cols if c in df_val.columns]
        X_val = df_val[available_cols].values
        y_val = df_val['target'].values
        
        # Test data
        df_test = pd.DataFrame({
            'target': splits['test_raw'],
            'timestamp': splits['test_timestamps']
        })
        for lag in self.config.get('n_lags', [24, 48, 168]):
            if lag < len(df_test):
                df_test[f'lag_{lag}'] = df_test['target'].shift(lag)
        
        df_test['hour'] = df_test['timestamp'].dt.hour
        df_test['hour_sin'] = np.sin(2 * np.pi * df_test['hour'] / 24)
        df_test['hour_cos'] = np.cos(2 * np.pi * df_test['hour'] / 24)
        df_test = df_test.dropna()
        
        available_cols_test = [c for c in feature_cols if c in df_test.columns]
        X_test = df_test[available_cols_test].values
        y_test = df_test['target'].values
        
        return X_train, y_train, X_val, y_val, X_test, y_test, feature_cols
    
    def run_all(self, splits, horizon):
        print("\n" + "="*60)
        print("RUNNING STRONG BASELINES WITH TUNING")
        print("="*60)
        
        train_raw = splits['train_raw']
        val_raw = splits['val_raw']
        test_raw = splits['test_raw']
        
        n_predict = len(test_raw) - horizon + 1
        if n_predict <= 0:
            print(f"  Warning: Not enough test data. n_predict={n_predict}")
            return {}, None
        
        print(f"  Test samples: {len(test_raw)}, Predictions: {n_predict}")
        
        y_test_aligned = np.zeros((n_predict, horizon))
        for h in range(horizon):
            start_idx = h
            end_idx = start_idx + n_predict
            if end_idx <= len(test_raw):
                y_test_aligned[:, h] = test_raw[start_idx:end_idx]
            else:
                y_test_aligned[:, h] = test_raw[start_idx:]
        
        results = {}
        
        # 1. Seasonal naive
        y_pred_sn = self._seasonal_naive(train_raw, n_predict, horizon)
        results['seasonal_naive'] = {
            'predictions': y_pred_sn,
            'rmse': np.sqrt(np.mean((y_pred_sn - y_test_aligned) ** 2)),
            'tuned': False
        }
        print(f"  Seasonal naive - RMSE: {results['seasonal_naive']['rmse']:.2f}")
        
        # 2. Drift method
        y_pred_drift = self._drift_method(train_raw, n_predict, horizon)
        results['drift'] = {
            'predictions': y_pred_drift,
            'rmse': np.sqrt(np.mean((y_pred_drift - y_test_aligned) ** 2)),
            'tuned': False
        }
        print(f"  Drift method - RMSE: {results['drift']['rmse']:.2f}")
        
        # 3. ARIMA with tuning
        try:
            y_pred_arima, best_order = self._tuned_arima(
                train_raw, val_raw, test_raw, n_predict, horizon
            )
            results['arima_tuned'] = {
                'predictions': y_pred_arima,
                'rmse': np.sqrt(np.mean((y_pred_arima - y_test_aligned) ** 2)),
                'tuned': True,
                'best_params': {'order': best_order}
            }
            print(f"  ARIMA (tuned) - RMSE: {results['arima_tuned']['rmse']:.2f}, order={best_order}")
        except Exception as e:
            print(f"  ARIMA failed: {e}")
        
        # 4. ETS with tuning
        try:
            y_pred_ets, best_period = self._tuned_ets(
                train_raw, val_raw, test_raw, n_predict, horizon
            )
            results['ets_tuned'] = {
                'predictions': y_pred_ets,
                'rmse': np.sqrt(np.mean((y_pred_ets - y_test_aligned) ** 2)),
                'tuned': True,
                'best_params': {'seasonal_period': best_period}
            }
            print(f"  ETS (tuned) - RMSE: {results['ets_tuned']['rmse']:.2f}, period={best_period}")
        except Exception as e:
            print(f"  ETS failed: {e}")
        
        # 5. Prophet
        if PROPHET_AVAILABLE:
            try:
                y_pred_prophet = self._prophet_forecast(
                    train_raw, splits['train_timestamps'], n_predict, horizon
                )
                results['prophet'] = {
                    'predictions': y_pred_prophet,
                    'rmse': np.sqrt(np.mean((y_pred_prophet - y_test_aligned) ** 2)),
                    'tuned': False
                }
                print(f"  Prophet - RMSE: {results['prophet']['rmse']:.2f}")
            except Exception as e:
                print(f"  Prophet failed: {e}")
        
        # 6. XGBoost with no leakage
        try:
            X_train, y_train, X_val, y_val, X_test, y_test, feat_names = self._prepare_tree_data_no_leakage(splits)
            
            if len(X_train) > 10 and len(X_val) > 10:
                # Quick tuning
                best_rmse = float('inf')
                best_model = None
                
                for n_est in [100]:
                    for depth in [6]:
                        for lr in [0.05]:
                            model = xgb.XGBRegressor(
                                n_estimators=n_est,
                                max_depth=depth,
                                learning_rate=lr,
                                random_state=BASE_SEED,
                                verbosity=0,
                                n_jobs=1,
                                tree_method='hist'
                            )
                            model.fit(X_train, y_train)
                            y_pred_val = model.predict(X_val)
                            rmse = np.sqrt(mean_squared_error(y_val, y_pred_val))
                            
                            if rmse < best_rmse:
                                best_rmse = rmse
                                best_model = model
                
                if best_model is not None:
                    y_pred_xgb = np.zeros((n_predict, horizon))
                    if len(X_test) >= n_predict:
                        y_pred_xgb[:, 0] = best_model.predict(X_test[:n_predict])
                    else:
                        y_pred_xgb[:, 0] = test_raw[-1]
                    
                    for h in range(1, horizon):
                        y_pred_xgb[:, h] = y_pred_xgb[:, h-1]
                    
                    results['xgboost_tuned'] = {
                        'predictions': y_pred_xgb,
                        'rmse': np.sqrt(np.mean((y_pred_xgb - y_test_aligned) ** 2)),
                        'tuned': True
                    }
                    print(f"  XGBoost (tuned) - RMSE: {results['xgboost_tuned']['rmse']:.2f}")
        except Exception as e:
            print(f"  XGBoost error: {e}")
        
        return results, y_test_aligned
    
    def _seasonal_naive(self, y_train, n_predict, horizon, season=24):
        if len(y_train) < season:
            return np.tile(y_train[-1], (n_predict, horizon))
        
        last_season = y_train[-season:]
        predictions = np.zeros((n_predict, horizon))
        for i in range(n_predict):
            for h in range(horizon):
                idx = (i + h) % season
                predictions[i, h] = last_season[idx]
        
        return predictions
    
    def _drift_method(self, y_train, n_predict, horizon):
        x_train = np.arange(len(y_train))
        slope = (y_train[-1] - y_train[0]) / max(1, len(y_train) - 1)
        intercept = y_train[0]
        
        predictions = np.zeros((n_predict, horizon))
        for i in range(n_predict):
            for h in range(horizon):
                predictions[i, h] = intercept + slope * (len(y_train) + i + h)
        
        return predictions
    
    def _tuned_arima(self, train_raw, val_raw, test_raw, n_predict, horizon):
        best_rmse = float('inf')
        best_order = (1,1,1)
        best_forecast = None
        
        p_values = [0, 1]
        d_values = [0, 1]
        q_values = [0, 1]
        
        train_val = np.concatenate([train_raw, val_raw])
        
        for p, d, q in itertools.product(p_values, d_values, q_values):
            try:
                model = ARIMA(train_raw, order=(p, d, q))
                fitted = model.fit()
                forecast = fitted.forecast(steps=n_predict + horizon)
                
                pred_val = np.zeros((n_predict, horizon))
                for i in range(n_predict):
                    pred_val[i] = forecast[i:i+horizon]
                
                rmse = np.sqrt(np.mean((pred_val - y_test_aligned) ** 2))
                
                if rmse < best_rmse:
                    best_rmse = rmse
                    best_order = (p, d, q)
                    best_forecast = pred_val
            except:
                continue
        
        if best_forecast is None:
            best_forecast = np.tile(train_val[-1], (n_predict, horizon))
        
        return best_forecast, best_order
    
    def _tuned_ets(self, train_raw, val_raw, test_raw, n_predict, horizon):
        best_rmse = float('inf')
        best_period = 24
        best_forecast = None
        
        periods = [24]
        train_val = np.concatenate([train_raw, val_raw])
        
        for period in periods:
            try:
                model = ExponentialSmoothing(
                    train_raw,
                    seasonal_periods=period,
                    trend='add',
                    seasonal='add'
                )
                fitted = model.fit()
                forecast = fitted.forecast(n_predict + horizon)
                
                pred_val = np.zeros((n_predict, horizon))
                for i in range(n_predict):
                    pred_val[i] = forecast[i:i+horizon]
                
                rmse = np.sqrt(np.mean((pred_val - y_test_aligned) ** 2))
                
                if rmse < best_rmse:
                    best_rmse = rmse
                    best_period = period
                    best_forecast = pred_val
            except:
                continue
        
        if best_forecast is None:
            best_forecast = np.tile(train_val[-1], (n_predict, horizon))
        
        return best_forecast, best_period
    
    def _prophet_forecast(self, train_raw, train_timestamps, n_predict, horizon):
        df_train = pd.DataFrame({
            'ds': train_timestamps,
            'y': train_raw
        })
        
        model = Prophet(
            yearly_seasonality=True,
            weekly_seasonality=True,
            daily_seasonality=True
        )
        model.fit(df_train)
        
        future = model.make_future_dataframe(periods=n_predict + horizon, freq='h')
        forecast = model.predict(future)
        y_pred_raw = forecast['yhat'].values[-n_predict - horizon:]
        
        y_pred = np.zeros((n_predict, horizon))
        for i in range(n_predict):
            y_pred[i] = y_pred_raw[i:i+horizon]
        
        return y_pred


# ============================================================================
# DEEP LEARNING MODELS - FIXED MULTI-HEAD ATTENTION
# ============================================================================

class BaseDLModel:
    def __init__(self, input_shape, config):
        self.input_shape = input_shape
        self.config = config
        self.model = None
        self.seed = config.get('seed', BASE_SEED)
        
    def build(self):
        raise NotImplementedError
    
    def compile(self):
        if self.model is None:
            self.build()
        
        optimizer = keras.optimizers.Adam(
            learning_rate=self.config['learning_rate'],
            clipnorm=self.config.get('gradient_clip', 1.0)
        )
        
        self.model.compile(
            optimizer=optimizer,
            loss='mse',
            metrics=['mae', tf.keras.metrics.RootMeanSquaredError(name='rmse')]
        )
    
    def train(self, X_train, y_train, X_val, y_val):
        patience = self.config.get('patience', 30)
        
        callbacks = [
            keras.callbacks.EarlyStopping(
                monitor='val_rmse',
                patience=patience,
                min_delta=self.config.get('min_delta', 0.0001),
                restore_best_weights=True,
                mode='min'
            ),
            keras.callbacks.ReduceLROnPlateau(
                monitor='val_rmse',
                factor=0.5,
                patience=patience // 2,
                min_lr=1e-6,
                mode='min'
            )
        ]
        
        history = self.model.fit(
            X_train, y_train,
            validation_data=(X_val, y_val),
            epochs=self.config['epochs'],
            batch_size=self.config['batch_size'],
            callbacks=callbacks,
            verbose=1,
            shuffle=False
        )
        
        return history
    
    def predict(self, X):
        return self.model.predict(X, verbose=0)
    
    def evaluate(self, X_test, y_test, scaler):
        y_pred_scaled = self.predict(X_test)
        
        n_samples = y_test.shape[0]
        horizon = self.config['forecast_horizon']
        
        y_test_flat = y_test.reshape(-1, 1)
        y_pred_flat = y_pred_scaled.reshape(-1, 1)
        
        y_test_orig = scaler.inverse_transform(y_test_flat).flatten().reshape(n_samples, horizon)
        y_pred_orig = scaler.inverse_transform(y_pred_flat).flatten().reshape(n_samples, horizon)
        
        metrics = self._calculate_metrics(y_test_orig, y_pred_orig)
        metrics = self._add_confidence_intervals_mbb(y_test_orig, y_pred_orig, metrics)
        
        return metrics, y_test_orig, y_pred_orig
    
    def _calculate_metrics(self, y_true, y_pred):
        y_true_flat = y_true.flatten()
        y_pred_flat = y_pred.flatten()
        
        mse = mean_squared_error(y_true_flat, y_pred_flat)
        rmse = np.sqrt(mse)
        mae = mean_absolute_error(y_true_flat, y_pred_flat)
        
        denominator = (np.abs(y_true_flat) + np.abs(y_pred_flat)) / 2
        denominator = np.maximum(denominator, 0.01 * np.mean(np.abs(y_true_flat)))
        smape = np.mean(2 * np.abs(y_true_flat - y_pred_flat) / denominator) * 100
        
        ss_res = np.sum((y_true_flat - y_pred_flat) ** 2)
        ss_tot = np.sum((y_true_flat - np.mean(y_true_flat)) ** 2)
        r2 = 1 - (ss_res / (ss_tot + 1e-10))
        
        per_horizon_rmse = []
        for h in range(y_true.shape[1]):
            rmse_h = np.sqrt(mean_squared_error(y_true[:, h], y_pred[:, h]))
            per_horizon_rmse.append(float(rmse_h))
        
        return {
            'rmse': float(rmse),
            'mae': float(mae),
            'smape': float(smape),
            'r2': float(r2),
            'per_horizon_rmse': per_horizon_rmse
        }
    
    def _add_confidence_intervals_mbb(self, y_true, y_pred, metrics, n_bootstrap=500):
        """
        Moving block bootstrap for time series confidence intervals with adaptive block size.
        """
        errors = (y_true - y_pred).flatten()
        
        def rmse_from_errors(e):
            return np.sqrt(np.mean(e ** 2))
        
        # Adaptive block size based on seasonal period
        block_size = self.config.get('seasonal_period', 24)
        n = len(errors)
        n_blocks = int(np.ceil(n / block_size))
        bootstrap_rmses = []
        
        for _ in range(n_bootstrap):
            blocks = []
            for _ in range(n_blocks):
                start = np.random.randint(0, max(1, n - block_size))
                blocks.append(errors[start:start+block_size])
            bootstrap_errors = np.concatenate(blocks)[:n]
            bootstrap_rmses.append(rmse_from_errors(bootstrap_errors))
        
        metrics['rmse_ci_lower'] = float(np.percentile(bootstrap_rmses, 2.5))
        metrics['rmse_ci_upper'] = float(np.percentile(bootstrap_rmses, 97.5))
        
        return metrics


class EnhancedLSTM(BaseDLModel):
    def build(self):
        inputs = keras.Input(shape=self.input_shape)
        
        # First LSTM with proper initialization
        if self.config.get('use_bidirectional', True):
            x = layers.Bidirectional(
                layers.LSTM(
                    self.config['lstm_units_1'],
                    return_sequences=True,
                    kernel_regularizer=keras.regularizers.l2(self.config['l2_regularization']),
                    recurrent_dropout=self.config['recurrent_dropout'],
                    kernel_initializer='glorot_uniform'
                )
            )(inputs)
        else:
            x = layers.LSTM(
                self.config['lstm_units_1'],
                return_sequences=True,
                kernel_regularizer=keras.regularizers.l2(self.config['l2_regularization']),
                recurrent_dropout=self.config['recurrent_dropout'],
                kernel_initializer='glorot_uniform'
            )(inputs)
        
        x = layers.BatchNormalization()(x)
        x = layers.Dropout(self.config['dropout_rate'])(x)
        
        # Second LSTM
        x = layers.LSTM(
            self.config['lstm_units_2'],
            return_sequences=True,
            kernel_regularizer=keras.regularizers.l2(self.config['l2_regularization']),
            recurrent_dropout=self.config['recurrent_dropout'],
            kernel_initializer='glorot_uniform'
        )(x)
        x = layers.BatchNormalization()(x)
        x = layers.Dropout(self.config['dropout_rate'])(x)
        
        # FIXED Multi-head attention with proper tensor operations
        if self.config.get('use_attention', True):
            if self.config.get('use_multi_head_attention', True):
                n_heads = self.config.get('attention_heads', 4)
                head_dim = self.config['lstm_units_2'] // n_heads
                
                # Project to multi-head space
                x_proj = layers.Dense(self.config['lstm_units_2'])(x)
                
                # Split into heads using tf.split (safe for symbolic tensors)
                x_heads = layers.Lambda(
                    lambda t: tf.split(t, n_heads, axis=-1)
                )(x_proj)
                
                attention_outputs = []
                for i in range(n_heads):
                    # Extract i-th head using Lambda (safe for symbolic tensors)
                    head = layers.Lambda(lambda t, idx=i: t[idx])(x_heads)
                    
                    # Attention weights for this head
                    attention = layers.Dense(head_dim, activation='tanh')(head)
                    attention = layers.Dense(1, activation='linear')(attention)
                    attention = layers.Flatten()(attention)
                    attention_weights = layers.Activation('softmax')(attention)
                    attention_weights = layers.RepeatVector(head_dim)(attention_weights)
                    attention_weights = layers.Permute([2, 1])(attention_weights)
                    
                    # Apply attention
                    head_out = layers.multiply([head, attention_weights])
                    head_out = layers.GlobalAveragePooling1D()(head_out)
                    attention_outputs.append(head_out)
                
                # Concatenate heads
                if len(attention_outputs) > 1:
                    x = layers.Concatenate()(attention_outputs)
                else:
                    x = attention_outputs[0]
                
                x = layers.Dense(self.config['lstm_units_2'])(x)
            else:
                # Single-head attention
                attention = layers.Dense(1, activation='tanh')(x)
                attention = layers.Flatten()(attention)
                attention = layers.Activation('softmax')(attention)
                attention = layers.RepeatVector(self.config['lstm_units_2'])(attention)
                attention = layers.Permute([2, 1])(attention)
                
                x = layers.multiply([x, attention])
                x = layers.GlobalAveragePooling1D()(x)
        else:
            x = layers.GlobalAveragePooling1D()(x)
        
        # Residual connection with proper scaling
        if self.config.get('use_residual', True):
            shortcut = layers.GlobalAveragePooling1D()(inputs)
            shortcut = layers.Dense(self.config['lstm_units_2'], kernel_initializer='he_normal')(shortcut)
            shortcut = layers.BatchNormalization()(shortcut)
            
            # Scale residual to match LSTM output variance
            x = layers.add([x, shortcut])
            x = layers.LayerNormalization()(x)  # Stabilize
        
        # Dense layers
        x = layers.Dense(
            self.config['dense_units_1'],
            activation='relu',
            kernel_regularizer=keras.regularizers.l2(self.config['l2_regularization']),
            kernel_initializer='he_normal'
        )(x)
        x = layers.Dropout(0.1)(x)
        x = layers.BatchNormalization()(x)
        
        x = layers.Dense(
            self.config['dense_units_2'],
            activation='relu',
            kernel_initializer='he_normal'
        )(x)
        x = layers.Dropout(0.1)(x)
        
        outputs = layers.Dense(self.config['forecast_horizon'], kernel_initializer='glorot_uniform')(x)
        
        self.model = keras.Model(inputs=inputs, outputs=outputs)


class SimpleLSTM(BaseDLModel):
    def build(self):
        inputs = keras.Input(shape=self.input_shape)
        
        x = layers.LSTM(64, return_sequences=True, kernel_initializer='glorot_uniform')(inputs)
        x = layers.Dropout(0.2)(x)
        
        x = layers.LSTM(32, return_sequences=False, kernel_initializer='glorot_uniform')(x)
        x = layers.Dropout(0.2)(x)
        
        x = layers.Dense(32, activation='relu', kernel_initializer='he_normal')(x)
        x = layers.Dense(16, activation='relu', kernel_initializer='he_normal')(x)
        
        outputs = layers.Dense(self.config['forecast_horizon'], kernel_initializer='glorot_uniform')(x)
        
        self.model = keras.Model(inputs=inputs, outputs=outputs)


class QuantileLSTM(BaseDLModel):
    """
    LSTM with quantile regression for proper prediction intervals.
    This is the CORRECT way to get uncertainty estimates.
    """
    def __init__(self, input_shape, config):
        super().__init__(input_shape, config)
        self.quantiles = config.get('quantiles', [0.1, 0.5, 0.9])
        self.n_quantiles = len(self.quantiles)
        
    def build(self):
        inputs = keras.Input(shape=self.input_shape)
        
        # Shared layers
        x = layers.LSTM(self.config['lstm_units_1'], return_sequences=True)(inputs)
        x = layers.Dropout(self.config['dropout_rate'])(x)
        
        x = layers.LSTM(self.config['lstm_units_2'], return_sequences=False)(x)
        x = layers.Dropout(self.config['dropout_rate'])(x)
        
        x = layers.Dense(self.config['dense_units_1'], activation='relu')(x)
        
        # Output for each quantile
        outputs = []
        for i, q in enumerate(self.quantiles):
            q_out = layers.Dense(self.config['forecast_horizon'], name=f'quantile_{q}')(x)
            outputs.append(q_out)
        
        # Concatenate all quantile outputs
        if len(outputs) > 1:
            output = layers.Concatenate(name='predictions')(outputs)
        else:
            output = outputs[0]
        
        self.model = keras.Model(inputs=inputs, outputs=output)
        
        # Custom loss function for quantile regression
        def quantile_loss_wrapper(y_true, y_pred):
            total_loss = 0
            for i, q in enumerate(self.quantiles):
                if self.n_quantiles > 1:
                    q_pred = y_pred[:, i*self.config['forecast_horizon']:(i+1)*self.config['forecast_horizon']]
                else:
                    q_pred = y_pred
                
                error = y_true - q_pred
                loss = tf.reduce_mean(tf.maximum(q * error, (q - 1) * error))
                total_loss += loss
            
            return total_loss / self.n_quantiles
        
        optimizer = keras.optimizers.Adam(learning_rate=self.config['learning_rate'])
        self.model.compile(
            optimizer=optimizer,
            loss=quantile_loss_wrapper,
            metrics=['mae']
        )
    
    def predict_with_uncertainty(self, X):
        """Generate predictions with proper quantile-based intervals."""
        outputs = self.model.predict(X, verbose=0)
        
        if self.n_quantiles > 1:
            predictions = {}
            for i, q in enumerate(self.quantiles):
                start = i * self.config['forecast_horizon']
                end = (i + 1) * self.config['forecast_horizon']
                predictions[f'q{q}'] = outputs[:, start:end]
            return predictions, predictions.get('q0.5', outputs)
        else:
            return {'q0.5': outputs}, outputs


class ProbabilisticLSTM(BaseDLModel):
    """
    Fixed probabilistic LSTM with proper NLL loss and variance clipping.
    """
    def __init__(self, input_shape, config):
        super().__init__(input_shape, config)
        self.log_2pi = np.log(2 * np.pi)
        
    def build(self):
        inputs = keras.Input(shape=self.input_shape)
        
        # Shared layers
        x = layers.LSTM(self.config['lstm_units_1'], return_sequences=True)(inputs)
        x = layers.Dropout(self.config['dropout_rate'])(x)
        
        x = layers.LSTM(self.config['lstm_units_2'], return_sequences=False)(x)
        x = layers.Dropout(self.config['dropout_rate'])(x)
        
        x = layers.Dense(self.config['dense_units_1'], activation='relu')(x)
        
        # Separate heads for mean and log variance
        mean = layers.Dense(self.config['forecast_horizon'], name='mean')(x)
        log_var = layers.Dense(self.config['forecast_horizon'], name='log_var')(x)
        
        # Clip log_var to prevent numerical instability
        log_var = layers.Lambda(
            lambda v: tf.clip_by_value(v, -5, 5),
            name='clipped_log_var'
        )(log_var)
        
        # Concatenate outputs
        outputs = layers.Concatenate(name='predictions')([mean, log_var])
        
        self.model = keras.Model(inputs=inputs, outputs=outputs)
        
        # Complete NLL loss with constant term
        def negative_log_likelihood(y_true, y_pred):
            mean = y_pred[:, :self.config['forecast_horizon']]
            log_var = y_pred[:, self.config['forecast_horizon']:]
            
            precision = tf.exp(-log_var)
            squared_error = (y_true - mean) ** 2
            
            # Complete NLL: 0.5 * (log(2) + log_var + precision * (y_true - mean)^2)
            return 0.5 * tf.reduce_mean(self.log_2pi + log_var + precision * squared_error)
        
        optimizer = keras.optimizers.Adam(learning_rate=self.config['learning_rate'])
        self.model.compile(
            optimizer=optimizer,
            loss=negative_log_likelihood,
            metrics=['mae']
        )
    
    def predict_with_uncertainty(self, X, quantiles=[0.1, 0.5, 0.9]):
        """Generate predictions with uncertainty intervals."""
        outputs = self.model.predict(X, verbose=0)
        mean = outputs[:, :self.config['forecast_horizon']]
        log_var = outputs[:, self.config['forecast_horizon']:]
        std = np.exp(0.5 * log_var)
        
        predictions = {}
        for q in quantiles:
            z_score = stats.norm.ppf(q)
            predictions[f'q{q}'] = mean + z_score * std
        
        return predictions, mean


class TransferLearningLSTM(BaseDLModel):
    def __init__(self, input_shape, config, source_weights=None):
        super().__init__(input_shape, config)
        self.source_weights = source_weights
    
    def build(self):
        inputs = keras.Input(shape=self.input_shape)
        
        x = layers.LSTM(self.config['lstm_units_1'], return_sequences=True, name='lstm1')(inputs)
        x = layers.Dropout(self.config['dropout_rate'])(x)
        
        x = layers.LSTM(self.config['lstm_units_2'], return_sequences=False, name='lstm2')(x)
        x = layers.Dropout(self.config['dropout_rate'])(x)
        
        x = layers.Dense(self.config['dense_units_1'], activation='relu', name='dense1')(x)
        x = layers.Dense(self.config['dense_units_2'], activation='relu', name='dense2')(x)
        
        outputs = layers.Dense(self.config['forecast_horizon'], name='output')(x)
        
        self.model = keras.Model(inputs=inputs, outputs=outputs)
        
        if self.source_weights is not None:
            try:
                self.model.load_weights(self.source_weights, by_name=True, skip_mismatch=True)
                print("  Loaded pre-trained weights from source country")
            except:
                print("  Could not load pre-trained weights")
    
    def freeze_feature_extractor(self, freeze=True):
        for layer in self.model.layers:
            if layer.name in ['lstm1', 'lstm2']:
                layer.trainable = not freeze


# ============================================================================
# MODEL FACTORY
# ============================================================================

class ModelFactory:
    @staticmethod
    def create_model(model_type, input_shape, config, source_weights=None):
        if model_type == 'enhanced_lstm':
            return EnhancedLSTM(input_shape, config)
        elif model_type == 'simple_lstm':
            return SimpleLSTM(input_shape, config)
        elif model_type == 'probabilistic_lstm':
            return ProbabilisticLSTM(input_shape, config)
        elif model_type == 'quantile_lstm':
            return QuantileLSTM(input_shape, config)
        elif model_type == 'transfer_lstm':
            return TransferLearningLSTM(input_shape, config, source_weights)
        else:
            raise ValueError(f"Unknown model type: {model_type}")


# ============================================================================
# HYPERPARAMETER OPTIMIZATION
# ============================================================================

class HyperparameterOptimizer:
    def __init__(self, config):
        self.config = config
        self.best_params = {}
        self.study = None
    
    def optimize(self, X_train, y_train, X_val, y_val, model_type='enhanced_lstm', n_trials=20):
        if not OPTUNA_AVAILABLE:
            print("Optuna not available. Using default parameters.")
            return self.config
        
        print(f"\nOptimizing {model_type} with {n_trials} trials...")
        
        def objective(trial):
            tf.keras.backend.clear_session()
            check_memory_and_clear(force=True)
            
            try:
                params = {
                    'learning_rate': trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True),
                    'batch_size': trial.suggest_categorical('batch_size', [32, 64]),
                    'dropout_rate': trial.suggest_float('dropout_rate', 0.1, 0.4),
                    'l2_regularization': trial.suggest_float('l2_regularization', 1e-5, 1e-3, log=True)
                }
                
                if model_type in ['enhanced_lstm', 'simple_lstm', 'probabilistic_lstm', 'quantile_lstm']:
                    params.update({
                        'lstm_units_1': trial.suggest_categorical('lstm_units_1', [64, 128]),
                        'lstm_units_2': trial.suggest_categorical('lstm_units_2', [32, 64])
                    })
                
                config_trial = self.config.copy()
                config_trial.update(params)
                
                model = ModelFactory.create_model(
                    model_type, X_train.shape[1:], config_trial
                )
                model.build()
                model.compile()
                
                history = model.model.fit(
                    X_train, y_train,
                    validation_data=(X_val, y_val),
                    epochs=30,
                    batch_size=config_trial['batch_size'],
                    callbacks=[keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)],
                    verbose=0,
                    shuffle=False
                )
                
                val_loss = min(history.history['val_loss'])
                
                del model
                tf.keras.backend.clear_session()
                check_memory_and_clear(force=True)
                
                return val_loss
                
            except Exception as e:
                print(f"Trial failed: {e}")
                tf.keras.backend.clear_session()
                check_memory_and_clear(force=True)
                return float('inf')
        
        self.study = optuna.create_study(direction='minimize')
        self.study.optimize(objective, n_trials=n_trials, catch=(Exception,))
        
        print(f"\nBest validation loss: {self.study.best_value:.4f}")
        print("Best parameters:")
        for key, value in self.study.best_params.items():
            print(f"  {key}: {value}")
        
        self.config.update(self.study.best_params)
        
        tf.keras.backend.clear_session()
        check_memory_and_clear(force=True)
        
        return self.config


# ============================================================================
# STATISTICAL VALIDATION
# ============================================================================

class StatisticalValidator:
    @staticmethod
    def compare_models(y_true, y_pred1, y_pred2, model1_name, model2_name, horizon=1):
        results = {}
        
        dm_stat, dm_p = diebold_mariano_test(y_true, y_pred1, y_pred2, h=horizon)
        results['dm_statistic'] = dm_stat
        results['dm_pvalue'] = dm_p
        results['dm_significant_005'] = dm_p < 0.05
        results['dm_significant_001'] = dm_p < 0.01
        
        e1 = np.abs(y_true - y_pred1)
        e2 = np.abs(y_true - y_pred2)
        w_stat, w_p = wilcoxon(e1 - e2)
        results['wilcoxon_statistic'] = w_stat
        results['wilcoxon_pvalue'] = w_p
        
        rmse1 = np.sqrt(np.mean((y_true - y_pred1) ** 2))
        rmse2 = np.sqrt(np.mean((y_true - y_pred2) ** 2))
        results['relative_improvement'] = (rmse1 - rmse2) / rmse1 * 100
        
        return results
    
    @staticmethod
    def multiple_comparison_correction(p_values, alpha=0.05, method='holm'):
        if method == 'bonferroni':
            n_tests = len(p_values)
            corrected_alpha = alpha / n_tests
            return [p < corrected_alpha for p in p_values]
        
        elif method == 'holm':
            return holm_bonferroni_correction(p_values, alpha)
        
        else:
            raise ValueError(f"Unknown correction method: {method}")


# ============================================================================
# EXPERIMENT RUNNER - FIXED VISUALIZATION
# ============================================================================

class ExperimentRunner:
    def __init__(self, config):
        self.config = config
        self.processor = LeakageFreeProcessor(config)
        self.results = {}
        self.baseline_results = {}
    
    def run(self):
        print("\n" + "="*70)
        print("ENERGY FORECASTING EXPERIMENT - MULTI-SEED")
        print("="*70)
        
        print("\n1. Loading data...")
        self.processor.load_data(self.config.get('data_path'))
        
        print("\n2. Preparing data splits...")
        country = self.config['country_code']
        splits = self.processor.prepare_splits(country)
        
        print("\n3. Running baseline models...")
        baselines, y_test_aligned = StrongBaselines(self.config).run_all(
            splits, self.config['forecast_horizon']
        )
        self.baseline_results = baselines
        
        with open(f"baselines_{country}.json", "w") as f:
            baseline_summary = {}
            for name, data in baselines.items():
                if 'rmse' in data:
                    baseline_summary[name] = {
                        'rmse': float(data['rmse']),
                        'tuned': data.get('tuned', False),
                        'best_params': data.get('best_params', {})
                    }
            json.dump(baseline_summary, f, indent=2)
        
        if self.config.get('optimize_hyperparameters', False) and OPTUNA_AVAILABLE:
            print("\n4. Optimizing hyperparameters...")
            optimizer = HyperparameterOptimizer(self.config)
            X_train_opt = splits['X_train'][:min(3000, len(splits['X_train']))]
            y_train_opt = splits['y_train'][:min(3000, len(splits['y_train']))]
            X_val_opt = splits['X_val'][:min(1000, len(splits['X_val']))]
            y_val_opt = splits['y_val'][:min(1000, len(splits['y_val']))]
            
            self.config = optimizer.optimize(
                X_train_opt, y_train_opt, X_val_opt, y_val_opt,
                model_type=self.config['model_type'],
                n_trials=self.config.get('n_trials', 20)
            )
        
        print(f"\n5. Running {self.config['n_seeds']} seeds...")
        
        seed_results = []
        
        for seed in range(self.config['n_seeds']):
            print(f"\n   Seed {seed + 1}/{self.config['n_seeds']}")
            
            set_seed(BASE_SEED + seed)
            check_memory_and_clear(force=True)
            
            input_shape = splits['X_train'].shape[1:]
            model = ModelFactory.create_model(
                self.config['model_type'], input_shape, self.config
            )
            model.build()
            model.compile()
            
            start_time = datetime.now()
            history = model.train(
                splits['X_train'], splits['y_train'],
                splits['X_val'], splits['y_val']
            )
            train_time = (datetime.now() - start_time).total_seconds()
            
            metrics, y_test_orig, y_pred_orig = model.evaluate(
                splits['X_test'], splits['y_test'],
                self.processor.target_scaler
            )
            
            test_results = self._run_statistical_tests(
                y_test_orig, y_pred_orig, baselines, splits
            )
            
            pred_df = pd.DataFrame({
                'actual': y_test_orig.flatten(),
                'predicted': y_pred_orig.flatten(),
                'seed': seed
            })
            pred_filename = f"predictions_{country}_{self.config['model_type']}_seed{seed}.csv"
            pred_df.to_csv(pred_filename, index=False)
            
            seed_results.append({
                'seed': seed,
                'metrics': metrics,
                'test_results': test_results,
                'train_time': train_time,
                'predictions': {
                    'y_test': y_test_orig,
                    'y_pred': y_pred_orig
                }
            })
            
            print(f"\n   Seed {seed + 1} Results:")
            print(f"     RMSE: {metrics['rmse']:.2f} [{metrics['rmse_ci_lower']:.2f}, {metrics['rmse_ci_upper']:.2f}]")
            print(f"     MAE: {metrics['mae']:.2f}")
            print(f"     R: {metrics['r2']:.4f}")
            print(f"     Time: {train_time:.1f}s")
            
            del model
            tf.keras.backend.clear_session()
            for _ in range(3):
                gc.collect()
            check_memory_and_clear(force=True)
        
        aggregated = self._aggregate_seed_results(seed_results)
        
        self.results[country] = {
            'by_seed': seed_results,
            'aggregated': aggregated,
            'baselines': baselines,
            'config': self.config
        }
        
        final_results = {
            'country': country,
            'model_type': self.config['model_type'],
            'n_seeds': self.config['n_seeds'],
            'aggregated_metrics': aggregated,
            'baselines': {k: v['rmse'] for k, v in baselines.items() if 'rmse' in v}
        }
        
        with open(f"final_results_{country}_{self.config['model_type']}.json", "w") as f:
            json.dump(final_results, f, indent=2)
        
        self._print_summary(country, aggregated, baselines)
        
        try:
            # FIXED: Pass only last seed's predictions for visualization
            self._save_visualizations(
                country, history, seed_results[-1]['predictions']['y_test'],
                seed_results[-1]['predictions']['y_pred'], aggregated
            )
        except Exception as e:
            print(f"Visualization error: {e}")
        
        return self.results
    
    def _run_statistical_tests(self, y_true, y_pred, baselines, splits):
        results = {}
        y_true_flat = y_true.flatten()
        y_pred_flat = y_pred.flatten()
        
        p_values = []
        baseline_names = []
        
        for name, data in baselines.items():
            if 'predictions' in data:
                y_base_flat = data['predictions'].flatten()
                min_len = min(len(y_true_flat), len(y_base_flat))
                
                if min_len > 0:
                    dm_stat, dm_p = diebold_mariano_test(
                        y_true_flat[:min_len],
                        y_pred_flat[:min_len],
                        y_base_flat[:min_len],
                        h=self.config['forecast_horizon']
                    )
                    
                    results[f'dm_vs_{name}_stat'] = dm_stat
                    results[f'dm_vs_{name}_p'] = dm_p
                    
                    p_values.append(dm_p)
                    baseline_names.append(name)
        
        if p_values:
            corrected = holm_bonferroni_correction(p_values, alpha=0.05)
            for i, name in enumerate(baseline_names):
                results[f'significant_vs_{name}'] = corrected[i]
        
        return results
    
    def _aggregate_seed_results(self, seed_results):
        aggregated = {}
        
        metrics_keys = ['rmse', 'mae', 'smape', 'r2']
        
        for key in metrics_keys:
            values = [r['metrics'][key] for r in seed_results]
            aggregated[f'{key}_mean'] = float(np.mean(values))
            aggregated[f'{key}_std'] = float(np.std(values))
            aggregated[f'{key}_min'] = float(np.min(values))
            aggregated[f'{key}_max'] = float(np.max(values))
        
        horizon = self.config['forecast_horizon']
        for h in range(horizon):
            values = [r['metrics']['per_horizon_rmse'][h] for r in seed_results]
            aggregated[f'rmse_h{h+1}_mean'] = float(np.mean(values))
            aggregated[f'rmse_h{h+1}_std'] = float(np.std(values))
        
        train_times = [r['train_time'] for r in seed_results]
        aggregated['train_time_mean'] = float(np.mean(train_times))
        aggregated['train_time_std'] = float(np.std(train_times))
        
        return aggregated
    
    def _save_visualizations(self, country, history, y_true, y_pred, metrics):
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        fig.suptitle(f'Forecasting Results - {country}', fontsize=16)
        
        if hasattr(history, 'history'):
            axes[0, 0].plot(history.history['loss'], label='Train')
            axes[0, 0].plot(history.history['val_loss'], label='Validation')
            axes[0, 0].set_title('Training History')
            axes[0, 0].set_xlabel('Epoch')
            axes[0, 0].set_ylabel('Loss')
            axes[0, 0].legend()
            axes[0, 0].grid(True, alpha=0.3)
        
        n_plot = min(200, y_true.shape[0])
        axes[0, 1].plot(y_true[:n_plot, 0], label='Actual', alpha=0.7)
        axes[0, 1].plot(y_pred[:n_plot, 0], label='Predicted', alpha=0.7)
        # FIXED: Remove incorrect uncertainty shading
        # Show only point predictions
        axes[0, 1].set_title('Predictions (h=1)')
        axes[0, 1].set_xlabel('Time')
        axes[0, 1].set_ylabel('Consumption')
        axes[0, 1].legend()
        axes[0, 1].grid(True, alpha=0.3)
        
        errors = (y_pred - y_true).flatten()
        axes[0, 2].hist(errors, bins=50, alpha=0.7, edgecolor='black')
        axes[0, 2].axvline(x=0, color='red', linestyle='--')
        axes[0, 2].set_title('Error Distribution')
        axes[0, 2].set_xlabel('Error')
        axes[0, 2].set_ylabel('Frequency')
        
        horizons = range(1, self.config['forecast_horizon'] + 1)
        rmse_means = [metrics[f'rmse_h{h}_mean'] for h in horizons]
        rmse_stds = [metrics[f'rmse_h{h}_std'] for h in horizons]
        
        axes[1, 0].bar(horizons, rmse_means, yerr=rmse_stds, capsize=5)
        axes[1, 0].set_title('RMSE by Horizon')
        axes[1, 0].set_xlabel('Horizon')
        axes[1, 0].set_ylabel('RMSE')
        axes[1, 0].grid(True, alpha=0.3)
        
        axes[1, 1].scatter(y_true.flatten(), y_pred.flatten(), alpha=0.3, s=1)
        min_val = min(y_true.min(), y_pred.min())
        max_val = max(y_true.max(), y_pred.max())
        axes[1, 1].plot([min_val, max_val], [min_val, max_val], 'r--')
        axes[1, 1].set_title('Actual vs Predicted')
        axes[1, 1].set_xlabel('Actual')
        axes[1, 1].set_ylabel('Predicted')
        axes[1, 1].grid(True, alpha=0.3)
        
        axes[1, 2].plot(errors[:n_plot*self.config['forecast_horizon']], alpha=0.5)
        axes[1, 2].axhline(y=0, color='red', linestyle='--')
        axes[1, 2].set_title('Residuals')
        axes[1, 2].set_xlabel('Time')
        axes[1, 2].set_ylabel('Residual')
        axes[1, 2].grid(True, alpha=0.3)
        
        plt.tight_layout()
        filename = f"visualizations_{country}_{self.config['model_type']}.png"
        plt.savefig(filename, dpi=150)
        plt.close()
        print(f"  Visualizations saved to {filename}")
    
    def _print_summary(self, country, aggregated, baselines):
        print("\n" + "="*70)
        print("EXPERIMENT SUMMARY")
        print("="*70)
        print(f"Country: {country}")
        print(f"Model: {self.config['model_type']}")
        print(f"Seeds: {self.config['n_seeds']}")
        
        print(f"\nPerformance (mean  std over seeds):")
        print(f"  RMSE: {aggregated['rmse_mean']:.2f}  {aggregated['rmse_std']:.2f}")
        print(f"  MAE: {aggregated['mae_mean']:.2f}  {aggregated['mae_std']:.2f}")
        print(f"  SMAPE: {aggregated['smape_mean']:.2f}%  {aggregated['smape_std']:.2f}%")
        print(f"  R: {aggregated['r2_mean']:.4f}  {aggregated['r2_std']:.4f}")
        
        print(f"\nPer-horizon RMSE:")
        for h in range(self.config['forecast_horizon']):
            print(f"  h={h+1}: {aggregated[f'rmse_h{h+1}_mean']:.2f}  {aggregated[f'rmse_h{h+1}_std']:.2f}")
        
        print("\nComparison with baselines (mean improvement):")
        sorted_baselines = sorted(
            baselines.items(),
            key=lambda x: x[1]['rmse'] if 'rmse' in x[1] else float('inf')
        )
        
        for name, data in sorted_baselines:
            if 'rmse' in data:
                impr = (data['rmse'] - aggregated['rmse_mean']) / data['rmse'] * 100
                tuned = " (tuned)" if data.get('tuned', False) else ""
                print(f"  vs {name:20s}{tuned}: {impr:6.1f}% better")


# ============================================================================
# TRANSFER LEARNING EXPERIMENT - FIXED SCALER
# ============================================================================

class TransferLearningExperiment:
    def __init__(self, config):
        self.config = config
        self.processor = LeakageFreeProcessor(config)
    
    def run(self, source_country, target_country):
        print("\n" + "="*70)
        print(f"TRANSFER LEARNING: {source_country} -> {target_country}")
        print("="*70)
        
        self.processor.load_data(self.config.get('data_path'))
        
        print(f"\n1. Training on source country: {source_country}")
        self.config['country_code'] = source_country
        source_splits = self.processor.prepare_splits(source_country)
        
        input_shape = source_splits['X_train'].shape[1:]
        source_model = TransferLearningLSTM(input_shape, self.config)
        source_model.build()
        source_model.compile()
        
        source_model.train(
            source_splits['X_train'], source_splits['y_train'],
            source_splits['X_val'], source_splits['y_val']
        )
        
        source_weights_path = f"source_model_{source_country}.h5"
        source_model.model.save_weights(source_weights_path)
        
        print(f"\n2. Fine-tuning on target country: {target_country}")
        self.config['country_code'] = target_country
        
        # FIXED: Create new processor for target to ensure proper scaling
        target_processor = LeakageFreeProcessor(self.config)
        target_processor.data = self.processor.data  # Share data but create new scalers
        target_splits = target_processor.prepare_splits(target_country)
        
        target_model = TransferLearningLSTM(
            input_shape, self.config, source_weights=source_weights_path
        )
        target_model.build()
        
        # Freeze feature extractor first
        target_model.freeze_feature_extractor(True)
        target_model.compile()
        
        target_model.train(
            target_splits['X_train'], target_splits['y_train'],
            target_splits['X_val'], target_splits['y_val']
        )
        
        # Fine-tune all layers
        target_model.freeze_feature_extractor(False)
        target_model.compile()
        
        target_model.train(
            target_splits['X_train'], target_splits['y_train'],
            target_splits['X_val'], target_splits['y_val']
        )
        
        metrics, y_test, y_pred = target_model.evaluate(
            target_splits['X_test'], target_splits['y_test'],
            target_processor.target_scaler  # Use target's scaler, not source's
        )
        
        print(f"\nTransfer Learning Results:")
        print(f"  RMSE: {metrics['rmse']:.2f}")
        print(f"  MAE: {metrics['mae']:.2f}")
        print(f"  R: {metrics['r2']:.4f}")
        
        return metrics


# ============================================================================
# MAIN ENTRY POINT
# ============================================================================

def main():
    parser = argparse.ArgumentParser(description='Energy Forecasting System')
    parser.add_argument('--config', type=str, default='config.yaml',
                        help='Path to configuration YAML file')
    parser.add_argument('--country', type=str, default=None,
                        help='Country code (overrides config)')
    parser.add_argument('--model', type=str, default=None,
                        help='Model type (overrides config)')
    parser.add_argument('--transfer', action='store_true',
                        help='Run transfer learning experiment')
    parser.add_argument('--source', type=str, default='DE',
                        help='Source country for transfer learning')
    parser.add_argument('--target', type=str, default='AT',
                        help='Target country for transfer learning')
    
    args = parser.parse_args()
    
    if os.path.exists(args.config):
        with open(args.config, 'r') as f:
            config = yaml.safe_load(f)
    else:
        config = Config.get_default_config()
        print(f"Config file {args.config} not found. Using default configuration.")
    
    if args.country:
        config['country_code'] = args.country
    if args.model:
        config['model_type'] = args.model
    
    print("\n" + "="*70)
    print("ENERGY FORECASTING SYSTEM v7.0 (All Critical Bugs Fixed - Journal Ready)")
    print("="*70)
    print("\nCONFIGURATION:")
    for key, value in config.items():
        if not isinstance(value, dict):
            print(f"  {key}: {value}")
    
    if args.transfer:
        experiment = TransferLearningExperiment(config)
        experiment.run(args.source, args.target)
    else:
        runner = ExperimentRunner(config)
        results = runner.run()
    
    print("\n" + "="*70)
    print("EXPERIMENT COMPLETE")
    print("="*70)


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\nInterrupted by user")
        sys.exit(0)
    except Exception as e:
        print(f"Error: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
